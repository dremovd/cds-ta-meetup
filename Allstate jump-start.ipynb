{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jump-start script for Competitive Data Science @ Tel Aviv Meetup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  train.csv.zip\n",
      "  inflating: train.csv               \n",
      "Archive:  test.csv.zip\n",
      "  inflating: test.csv                \n"
     ]
    }
   ],
   "source": [
    "# unzip -fo replace files if they are already exists\n",
    "\n",
    "!unzip -fo train.csv.zip\n",
    "!unzip -fo test.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((188318, 132),\n",
       " Index([u'id', u'cat1', u'cat2', u'cat3', u'cat4', u'cat5', u'cat6', u'cat7',\n",
       "        u'cat8', u'cat9',\n",
       "        ...\n",
       "        u'cont6', u'cont7', u'cont8', u'cont9', u'cont10', u'cont11', u'cont12',\n",
       "        u'cont13', u'cont14', u'loss'],\n",
       "       dtype='object', length=132))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((125546, 131),\n",
       " Index([u'id', u'cat1', u'cat2', u'cat3', u'cat4', u'cat5', u'cat6', u'cat7',\n",
       "        u'cat8', u'cat9',\n",
       "        ...\n",
       "        u'cont5', u'cont6', u'cont7', u'cont8', u'cont9', u'cont10', u'cont11',\n",
       "        u'cont12', u'cont13', u'cont14'],\n",
       "       dtype='object', length=131))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape, test.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "### Let's look at ID numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([     1,      2,      5, ..., 587630, 587632, 587633]),\n",
       " array([     4,      6,      9, ..., 587627, 587629, 587634]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['id'].values, test['id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID's are interleaved. So, we can use it as feature to catch dependency on the order of data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are target values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2213.18,  1283.6 ,  3005.09, ...,  5762.64,  1562.87,  4751.72])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['loss'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3037.3376856699833, 2115.5699999999997)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['loss'].mean(), train['loss'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probably loss is in dollars\n",
    "### Let's look to the target distribution itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfkAAAFZCAYAAACbqlYKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAG4pJREFUeJzt3X9s1dX9x/EX34qJQMuP/rh0nSnxopMt1f3RKQFjK/0F\nlvKjLVs254zdhiZLYdLMZQ0bYR2YIDUz+0PpcrfFZVnMGDDp9YvOMloQqRoH7UQTrWOFVi6F0tIi\ncqH3fP/g27veWuC2vT/PfT4SE+65t/dzzj3XvnrvOZ/3Z4oxxggAAFjnf6LdAQAAEB6EPAAAliLk\nAQCwFCEPAIClCHkAACxFyAMAYClCHgAASxHyAABYKiwh//bbb+uRRx7Rpk2b9M4774TjEAAA4CbC\nEvJTpkzR9OnT5fV6NXfu3HAcAgAA3MSUYMra1tbW6sCBA0pNTdXevXv97S0tLdq6dauMMaqoqNDa\ntWsDfu7cuXN65plntH379tD3HAAA3FBQn+TLy8vlcrkC2nw+n+rq6uRyudTY2Ci3262Ojo6AxyQn\nJ+vKlSuh6y0AAAjaLcE8KDc3V11dXQFtbW1tys7OVlZWliSptLRUTU1Ncjqd+vvf/66DBw9qcHBQ\n3/3ud0PfawAAcFNBhfxYPB6PMjMz/bcdDofa29slSUVFRSoqKgr6uYwxmjJlykS7AgAAxjDhkA+l\nKVOmqKdnINrdiJr09GTGz/ij3Y2oSeTxJ/LYJcafnp4c9mNMeHe9w+FQd3e3/7bH41FGRkZIOgUA\nACYv6JAfvQk/JydHnZ2d6urqktfrldvtVkFBQcg7CAAAJiaor+tramrU2tqqvr4+5efnq7q6WhUV\nFdq4caOqqqpkjFFlZaWcTme4+wsAAIIUVMjX19eP2Z6Xl6e8vLyQdggAAIQGtesBALAUIQ8AgKUI\neQAALEXIAwBgKUIeAABLEfIAAFiKkAcAwFIxUbt+pKGhIZ048UlA27x5dygpKSlKPQIAID7FXMif\nOPGJ1j/7iqbNvFYH/7P+M3r+JyvkdN4Z5Z4BABBfYi7kJWnazAzNmJ0V7W4AABDXWJMHAMBShDwA\nAJYi5AEAsFRMrMn/7+vNanu/Q5LUc+a0pFnR7RAAABaIiZD/++H39dHAtY12g+c/j3JvAACwA1/X\nAwBgKUIeAABLEfIAAFiKkAcAwFKEPAAAliLkAQCwFCEPAIClCHkAACxFyAMAYKmYqHh3I8bnU2fn\nfwLa5s27Q0lJSVHqEQAA8SHmQ/7SQI/qXz6raTM/lSR91n9Gz/9khZzOO6PcMwAAYlvMh7wkTZuZ\noRmzs6LdDQAA4gpr8gAAWIqQBwDAUoQ8AACWIuQBALAUIQ8AgKUIeQAALEXIAwBgKUIeAABLEfIA\nAFiKkAcAwFKEPAAAloqL2vUjcVU6AACCE3chz1XpAAAITtyFvMRV6QAACAZr8gAAWIqQBwDAUoQ8\nAACWIuQBALAUIQ8AgKUIeQAALEXIAwBgKUIeAABLEfIAAFgqbCF/6dIlVVRUqLm5OVyHAAAANxC2\nsra//e1v9fDDD4fr6f24YA0AAGMLKuRra2t14MABpaamau/evf72lpYWbd26VcYYVVRUaO3atZKk\nw4cPa/78+bp8+bKMMeHp+f/jgjUAAIwtqK/ry8vL5XK5Atp8Pp/q6urkcrnU2Ngot9utjo4OSVJr\na6uOHTumxsZG/eUvfwl9r0cZvmDNjNlZmjYzI+zHAwAgHgT1ST43N1ddXV0BbW1tbcrOzlZW1rWr\nwZWWlqqpqUlOp1NPPfWUJGnPnj2aPXt2iLsMAACCMeE1eY/Ho8zMTP9th8Oh9vb2gMesWrVq4j2b\nhDlzZig9PTkqx56oeOtvqDF+xp+oEnnsEuMPt7i8nvzN9PYOqqdnINrdCFp6enJc9TfUGD/jT9Tx\nJ/LYJcYfiT9wJnwKncPhUHd3t/+2x+NRRgbr4QAAxIqgQ370LvmcnBx1dnaqq6tLXq9XbrdbBQUF\nIe8gAACYmKC+rq+pqVFra6v6+vqUn5+v6upqVVRUaOPGjaqqqpIxRpWVlXI6neHuLwAACFJQIV9f\nXz9me15envLy8kLaIQAAEBrUrgcAwFKEPAAAlrLuFDpq2QMAcI11IU8tewAArrEu5KX/1rIHACCR\nsSYPAIClCHkAACxFyAMAYClCHgAASxHyAABYipAHAMBShDwAAJYi5AEAsBQhDwCApQh5AAAsZWVZ\n25G4YA0AIFFZH/JcsAYAkKisD3mJC9YAABITa/IAAFiKkAcAwFKEPAAAliLkAQCwFCEPAIClCHkA\nACxFyAMAYKmEOE9+pNEV8Kh+BwCwVcKF/MgKeFS/AwDYLOFCXqICHgAgMbAmDwCApQh5AAAsRcgD\nAGApQh4AAEsR8gAAWIqQBwDAUoQ8AACWIuQBALBUQhbDGTa6xK1EmVsAgD0SOuRHlriVRJlbAIBV\nEjrkJUrcAgDsxZo8AACWIuQBALAUIQ8AgKUIeQAALEXIAwBgKUIeAABLEfIAAFiKkAcAwFIJXwxn\nJMrcAgBsQsiPQJlbAIBNCPlRKHMLALBFWEK+o6NDL730kvr6+rRw4UJ9+9vfDsdhAADADYRl453T\n6dTmzZv161//Wv/85z/DcQgAAHATQYV8bW2tFi1apLKysoD2lpYWLV26VCUlJWpoaAi4b//+/Xri\niSeUl5cXut4CAICgBRXy5eXlcrlcAW0+n091dXVyuVxqbGyU2+1WR0eH//4lS5aooaFBr7zySmh7\nDAAAghLUmnxubq66uroC2tra2pSdna2srGub1EpLS9XU1CSn06m3335br7/+urxeL5/kAQCIkglv\nvPN4PMrMzPTfdjgcam9vlyTdd999uu+++ybfOwAAMGGcQncTc+bMUHp6ctiPE4ljxDLGz/gTVSKP\nXWL84TbhkHc4HOru7vbf9ng8ysjICEmnYoXx+XT06Pvq7R30t4WjAl56erJ6egZC+pzxhPEz/kQd\nfyKPXWL8kfgDJ+iQN8YE3M7JyVFnZ6e6urqUnp4ut9ut5557LuQdjCYq4AEA4llQIV9TU6PW1lb1\n9fUpPz9f1dXVqqio0MaNG1VVVSVjjCorK+V0OsPd34ijAh4AIF4FFfL19fVjtufl5bF7HgCAGMWl\nZgEAsBQhDwCApQh5AAAsRcgDAGApQh4AAEsR8gAAWIqQBwDAUtSuHwfj86mz8z8BbeEocwsAQCgQ\n8uNAmVsAQDwh5MeJMrcAgHjBmjwAAJYi5AEAsBQhDwCApQh5AAAsRcgDAGApQh4AAEtxCt0kUBwH\nABDLCPlJoDgOACCWEfKTRHEcAECsYk0eAABLEfIAAFiKkAcAwFKEPAAAliLkAQCwFLvrQ4jz5gEA\nsYSQDyHOmwcAxBJCPsQ4bx4AECtYkwcAwFKEPAAAliLkAQCwFCEPAIClCHkAACxFyAMAYClCHgAA\nSxHyAABYipAHAMBSVLwLo9G17KljDwCIJEI+jEbWsqeOPQAg0gj5MKOWPQAgWliTBwDAUoQ8AACW\nIuQBALAUa/IRMnqnvcRuewBAeBHyETJyp70kdtsDAMKOkI8gdtoDACKJNXkAACxFyAMAYClCHgAA\nSxHyAABYipAHAMBShDwAAJYK2yl0b7zxhpqbm3Xx4kVVVFRo8eLF4ToUAAAYQ9hCvrCwUIWFhbpw\n4YK2bdtGyI8ysgLe+fMz1Ns7SAU8AEBIBR3ytbW1OnDggFJTU7V3715/e0tLi7Zu3SpjjCoqKrR2\n7dqAn3vhhRf0yCOPhK7HlqACHgAg3IJeky8vL5fL5Qpo8/l8qqurk8vlUmNjo9xutzo6Ovz3b9++\nXQ8++KAWLFgQuh5bZLgC3ozZWZo2MyPa3QEAWCbokM/NzVVKSkpAW1tbm7Kzs5WVlaWpU6eqtLRU\nTU1NkqQ//vGPeuutt/Taa6/p5ZdfDm2vAQDATU1qTd7j8SgzM9N/2+FwqL29XZL06KOP6tFHH51c\n7xLMnDkzlJ6eHO1uREWijnsY40/c8Sfy2CXGH25coCZGGJ9PR4++r97eQX9bomzES09PVk/PQLS7\nETWMP3HHn8hjlxh/JP7AmVTIOxwOdXd3+297PB5lZLC2PBFsxAMAhNq4iuEYYwJu5+TkqLOzU11d\nXfJ6vXK73SooKAhpBxMJG/EAAKEU9Cf5mpoatba2qq+vT/n5+aqurlZFRYU2btyoqqoqGWNUWVkp\np9MZzv4CAIAgBR3y9fX1Y7bn5eUpLy8vZB0CAAChQe16AAAsRcgDAGApQh4AAEsR8gAAWIqQBwDA\nUlS8i1EjL0U7LFEq4AEAQoOQj1FUwAMATBYhH8OGK+ABADARrMkDAGApQh4AAEsR8gAAWIqQBwDA\nUoQ8AACWIuQBALAUIQ8AgKU4Tz5OUAEPADBehHycoAIeAGC8CPk4QgU8AMB4sCYPAICl+CQfp0av\n0Q8NDUmaoqSka3+3sV4PACDk49ToNfpzpz7QbcmpmjYzg/V6AIAkQj6ujVyj/6zfw5o9ACAAa/IA\nAFiKkAcAwFKEPAAAliLkAQCwFCEPAIClCHkAACxFyAMAYClCHgAASxHyAABYipAHAMBShDwAAJYi\n5AEAsBQhDwCApQh5AAAsxaVmLWR8PnV2/iegbd68O5SUlBSlHgEAooGQt9ClgR7Vv3xW02Z+Kkn6\nrP+Mnv/JCjmdd0a5ZwCASCLkLTVtZoZmzM6KdjcAAFHEmjwAAJYi5AEAsBQhDwCApQh5AAAsRcgD\nAGApdtcnAM6bB4DERMgnAM6bB4DERMgnCM6bB4DEw5o8AACWIuQBALAUIQ8AgKXCsiZ/8uRJvfji\nixocHNTzzz8fjkNgEthtDwCJISwhf/vtt2vLli1av359OJ4ek8RuewBIDEF9XV9bW6tFixaprKws\noL2lpUVLly5VSUmJGhoawtJBhMfwbvsZs7M0bWZGtLsDAAiDoEK+vLxcLpcroM3n86murk4ul0uN\njY1yu93q6OgIeIwxJnQ9BQAA4xJUyOfm5iolJSWgra2tTdnZ2crKytLUqVNVWlqqpqYmSVJfX582\nbdqkDz/8kE/4cWB4jb6j4yP/f0NDQ9HuFgBgkia8Ju/xeJSZmem/7XA41N7eLkmaNWuWNm/ePPne\nISLGWqP/4zPf0V133RWxPqSnJ0fsWLGI8Sfu+BN57BLjDzcq3kHSFyvi9fYOqqdnICLHTk9Pjtix\nYhHjT9zxJ/LYJcYfiT9wJnyevMPhUHd3t/+2x+NRRgYbuAAAiBVBh/zoTXQ5OTnq7OxUV1eXvF6v\n3G63CgoKQt5BAAAwMUF9XV9TU6PW1lb19fUpPz9f1dXVqqio0MaNG1VVVSVjjCorK+V0OsPdXwAA\nEKSgQr6+vn7M9ry8POXl5YW0QwAAIDSoXQ8AgKUIeQAALEXIAwBgKUIeAABLEfIAAFiKkAcAwFKE\nPAAAlqJ2Pb5g+Kp0I82bd4eSkpKi1CMAwEQQ8viCsa5K9/xPVsjpvDPKPQMAjAchjzGNviodACD+\nsCYPAIClCHkAACzF1/W4qdEb8YaGhiRNUVLStb8RR27KGxoa0okTnwT8PJv2ACA6CHnc1OiNeOdO\nfaDbklM1bWbGFzblnTjxidY/+4qmzcyQxKY9AIgmQh5BGbkR77N+zw035rFpDwBiA2vyAABYipAH\nAMBShDwAAJZiTR5xg537ADA+hDziBjv3AWB8CHnEFXbuA0DwWJMHAMBShDwAAJYi5AEAsBQhDwCA\npQh5AAAsxe56TMroK9SN/PdEcC48AIQOIY9JGesKdalfXjDh5+NceAAIHUIekzb6CnWhfD4AwMSx\nJg8AgKUIeQAALEXIAwBgKUIeAABLEfIAAFiKkAcAwFKEPAAAluI8eYTV6Ip4Uugq2I33uW9WTW/0\n/fFaaY+qgQCGEfIIq9EV8UJZwW68z32zanoj74/nSntUDQQwjJBH2IWzgt14n/tmj7el2p4t4wAw\nOazJAwBgKUIeAABLEfIAAFiKkAcAwFKEPAAAliLkAQCwFCEPAIClCHkAACxFyAMAYClCHgAASxHy\nAABYKiy16y9duqTNmzfr1ltv1Te+8Q2VlZWF4zAAAOAGwvJJ/vXXX9fSpUv1y1/+Uvv37w/HIQAA\nwE0EFfK1tbVatGjRFz6Rt7S0aOnSpSopKVFDQ4O/3ePxaO7cudcO8D+sCAAAEA1BJXB5eblcLldA\nm8/nU11dnVwulxobG+V2u9XR0SFJmjt3rjweT+h7CwAAghZUyOfm5iolJSWgra2tTdnZ2crKytLU\nqVNVWlqqpqYmSVJRUZH27dunzZs366GHHgp9rwEAwE1NeOOdx+NRZmam/7bD4VB7e7sk6bbbbtMz\nzzwz+d7BOsbnU2fnf/y3h4aGdPbsDPX3X5KkgPtiydDQkE6c+CSgbd68O5SUlDShx4+8//z5GUpJ\nybjuc9nieq9JOJ/b9td0tHh5HYb7ef78DPX2DkqKzX7aYIoxxgTzwK6uLj355JPau3evJOm1117T\noUOHVFdXJ0n629/+pvb2dm3cuDF8vQUAAEGb8K44h8Oh7u5u/22Px6OMjIyQdAoAAExe0CE/+gN/\nTk6OOjs71dXVJa/XK7fbrYKCgpB3EAAATExQX9fX1NSotbVVfX19SktLU3V1tSoqKtTc3KytW7fK\nGKPKykqtXbs2En0GAABBCHpNHgAAxBcq1QAAYClCHgAAS0U95K9XGjfenD59Wt/73vdUWlqqsrIy\nvfTSS5Kk/v5+VVVVqaSkRN///vc1MDDg/5lf/epXKi4u1sqVK/XBBx/423fv3q2SkhKVlJRoz549\n/vb3339fZWVlKikp0ZYtWyI3uHHw+XxavXq1nnzySUnSqVOn9M1vflMlJSXasGGDrl69Kknyer16\n6qmnVFxcrG9961sBZ2rs2LFDxcXFWrZsmQ4dOuRvj/X3ysDAgNatW6dly5aptLRUx44dS6j5/8Mf\n/qDly5errKxMNTU18nq9Vs//WOW+IzHfNzpGpIw19m3btmnZsmVauXKlqqurNTg46L9vvHM6kfdN\nJF2v1Lsk/e53v9Pdd9+tvr4+f1tU595E0dDQkCksLDSnTp0yXq/XrFixwnz88cfR7NKEnTlzxhw/\nftwYY8zg4KApLi42H3/8sdm2bZtpaGgwxhizY8cO8+yzzxpjjDlw4ID54Q9/aIwx5ujRo2bNmjXG\nGGP6+vpMQUGBuXDhgunv7/f/2xhjKisrzbFjx4wxxvzgBz8wLS0tER1jMH7/+9+bmpoa88QTTxhj\njFm/fr159dVXjTHG/OIXvzB//vOfjTHG/OlPfzKbNm0yxhjjdrvNj3/8Y2OMMR999JFZuXKluXLl\nijl58qQpLCw0Pp8vLt4rP/3pT83OnTuNMcZcuXLFXLhwIWHm//Tp02bJkiXm8uXLxphr875r1y6r\n5/+dd94xx48fN8uXL/e3RWK+r3eMSBpr7G+++aYZGhoyxhjz7LPPmu3btxtjJjan433fRNpY4zfG\nmE8//dRUVVWZhx56yJw/f94YE/25j+on+RuVxo036enpWrBggSRp+vTpcjqd8ng8ampq0urVqyVJ\nq1ev9o+vqalJq1atkiTde++9GhgY0NmzZ3Xo0CEtXrxYycnJSklJ0eLFi3Xw4EH19PTo4sWLuuee\neyRJq1at0htvvBGFkV7f6dOn1dzcrDVr1vjbjhw5opKSEknXxj/c55GvS0lJiY4cOSJJ2r9/vx5+\n+GHdcsst+vKXv6zs7Gy1tbXF/HtlcHBQ7777rioqKiRJt9xyi5KTkxNq/n0+ny5duqSrV6/q888/\nV0ZGhlpbW62d/7HKfUdivkcfIxrvg7HGvmjRIv8Fyb7+9a/r9OnTkiY2p8H+3njrrbciMt7Rxhq/\nJG3dulVPP/10QFu05z6qIT9WadwzZ85EsUehcerUKX344Ye69957de7cOaWlpUm69ofAuXPnJEln\nzpzxX6lP+u9FfcZ6TYbbRz5+uD2WDL/Bp0yZIkk6f/68Zs6c6f8ff+SFi0aOPykpScnJyerr67vh\n+GP5vXLq1CnNnj1bP/vZz7R69Wr9/Oc/16VLlxJm/h0Ohx5//HHl5+frwQcfVHJysr761a8qJSUl\nIeZ/WG9vb9jne/R7qre3N+zjGq+dO3cqLy9P0ti/5280p+P5vZGSkhLwtXg0NTU1KTMzU1/5ylcC\n2qM991Ffk7fNxYsXtW7dOtXW1mr69On+wBs2+vYwE+dnMh44cEBpaWlasGBBwFiCHVe8j//q1as6\nfvy4vvOd72j37t267bbb1NDQkDDzf+HCBTU1Nekf//iHDh48qEuXLungwYNB/3y8j/96IjHf1ztG\ntLzwwguaOnWqli9fPuHniLffG59//rl27Nih6urqmz420nMf1ZC3rTTu1atXtW7dOq1cuVKFhYWS\npNTUVJ09e1aS1NPTozlz5kiSMjIy/F9nSde+6nY4HF94TUa2f/rpp/52j8cjh8MRiWEF5b333tP+\n/ftVUFDgL560ZcsWDQwMyOfzSfrvWKTA8Q8NDWlwcFCzZs36wjiv97rE2ntl7ty5mjt3rnJyciRJ\nxcXFOn78eMLM/+HDh3X77bdr1qxZSkpKUmFhod577z1duHAhIeZ/WCTmOy0tbcxjxIJdu3apublZ\n9fX1/rbxzuns2bPH/b6JtuHqrytXrtSSJUvk8XhUXl6uc+fORX3uoxrytpXGra2t1fz58/XYY4/5\n25YsWaJdu3ZJuraTcnh8BQUF/t2UR48eVUpKitLS0vTAAw/o8OHDGhgYUH9/vw4fPqwHHnhA6enp\nSk5OVltbm4wx2rNnT0y9Vhs2bNCBAwfU1NSk5557Tvfff7+2b9+u+++/X/v27ZMUOP4lS5Zo9+7d\nkqR9+/Zp4cKF/vZXX31VXq9XJ0+eVGdnp+65556Yf6+kpaUpMzNT//73vyVdW1OcP39+wsz/l770\nJR07dkyXL1+WMUZHjhzRnXfeaf38j/5UFon5vt4xIm302FtaWuRyufTCCy/o1ltv9bdPZE4XLlw4\nrvdNNIwc/1133aU333xTTU1N2r9/vxwOh3bv3q3U1NToz/24txWGWHNzsykuLjZFRUVmx44d0e7O\nhL377rvm7rvvNitWrDArV640q1atMs3Nzeb8+fPmscceM8XFxebxxx83/f39/p/ZvHmzKSwsNGVl\nZeZf//qXv/2vf/2rKSoqMsXFxWb37t3+9vb2drN8+XJTVFRk6urqIjq+8WhtbfXvru/s7DSVlZWm\nuLjYrF+/3ni9XmOMMZcvXzbr1q0zRUVFZs2aNebkyZP+n3/xxRdNYWGhWbp0qTl48KC/PdbfKx98\n8IEpLy83K1asMD/60Y/MhQsXEmr+f/Ob35ilS5ea5cuXm6efftp4vV6r53/Dhg1m8eLF5mtf+5rJ\ny8szO3fuNH19fWGf7xu9pyJlrLEXFRWZ/Px8s2rVKrNq1Sr/Lnhjxj+nE3nfRNJY4x9pyZIl/t31\nxkR37ilrCwCApdh4BwCApQh5AAAsRcgDAGApQh4AAEsR8gAAWIqQBwDAUoQ8AACWIuQBALDU/wHw\nSC0/3QyUIgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d318e7510>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(train['loss'], bins = 100, log = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution is skewed, let's look at target logarithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFZCAYAAAC173eYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBgDAEIQ2AACGILQBADDE/wE2JIEY9gFmlwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d8c027250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "_ = plt.hist(np.log(train['loss']), bins = 100, log = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How dataset features looks like? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id 188318\n",
      "cat1 ['A' 'B']\n",
      "cat2 ['A' 'B']\n",
      "cat3 ['A' 'B']\n",
      "cat4 ['A' 'B']\n",
      "cat5 ['A' 'B']\n",
      "cat6 ['A' 'B']\n",
      "cat7 ['A' 'B']\n",
      "cat8 ['A' 'B']\n",
      "cat9 ['A' 'B']\n",
      "cat10 ['A' 'B']\n",
      "cat11 ['A' 'B']\n",
      "cat12 ['A' 'B']\n",
      "cat13 ['A' 'B']\n",
      "cat14 ['A' 'B']\n",
      "cat15 ['A' 'B']\n",
      "cat16 ['A' 'B']\n",
      "cat17 ['A' 'B']\n",
      "cat18 ['A' 'B']\n",
      "cat19 ['A' 'B']\n",
      "cat20 ['A' 'B']\n",
      "cat21 ['A' 'B']\n",
      "cat22 ['A' 'B']\n",
      "cat23 ['A' 'B']\n",
      "cat24 ['A' 'B']\n",
      "cat25 ['A' 'B']\n",
      "cat26 ['A' 'B']\n",
      "cat27 ['A' 'B']\n",
      "cat28 ['A' 'B']\n",
      "cat29 ['A' 'B']\n",
      "cat30 ['A' 'B']\n",
      "cat31 ['A' 'B']\n",
      "cat32 ['A' 'B']\n",
      "cat33 ['A' 'B']\n",
      "cat34 ['A' 'B']\n",
      "cat35 ['A' 'B']\n",
      "cat36 ['A' 'B']\n",
      "cat37 ['A' 'B']\n",
      "cat38 ['A' 'B']\n",
      "cat39 ['A' 'B']\n",
      "cat40 ['A' 'B']\n",
      "cat41 ['A' 'B']\n",
      "cat42 ['A' 'B']\n",
      "cat43 ['A' 'B']\n",
      "cat44 ['A' 'B']\n",
      "cat45 ['A' 'B']\n",
      "cat46 ['A' 'B']\n",
      "cat47 ['A' 'B']\n",
      "cat48 ['A' 'B']\n",
      "cat49 ['A' 'B']\n",
      "cat50 ['A' 'B']\n",
      "cat51 ['A' 'B']\n",
      "cat52 ['A' 'B']\n",
      "cat53 ['A' 'B']\n",
      "cat54 ['A' 'B']\n",
      "cat55 ['A' 'B']\n",
      "cat56 ['A' 'B']\n",
      "cat57 ['A' 'B']\n",
      "cat58 ['A' 'B']\n",
      "cat59 ['A' 'B']\n",
      "cat60 ['A' 'B']\n",
      "cat61 ['A' 'B']\n",
      "cat62 ['A' 'B']\n",
      "cat63 ['A' 'B']\n",
      "cat64 ['A' 'B']\n",
      "cat65 ['A' 'B']\n",
      "cat66 ['A' 'B']\n",
      "cat67 ['A' 'B']\n",
      "cat68 ['A' 'B']\n",
      "cat69 ['A' 'B']\n",
      "cat70 ['A' 'B']\n",
      "cat71 ['A' 'B']\n",
      "cat72 ['A' 'B']\n",
      "cat73 ['A' 'B' 'C']\n",
      "cat74 ['A' 'B' 'C']\n",
      "cat75 ['A' 'B' 'C']\n",
      "cat76 ['A' 'B' 'C']\n",
      "cat77 ['A' 'B' 'C' 'D']\n",
      "cat78 ['A' 'B' 'C' 'D']\n",
      "cat79 ['A' 'B' 'C' 'D']\n",
      "cat80 ['A' 'B' 'C' 'D']\n",
      "cat81 ['A' 'B' 'C' 'D']\n",
      "cat82 ['A' 'B' 'C' 'D']\n",
      "cat83 ['A' 'B' 'C' 'D']\n",
      "cat84 ['A' 'B' 'C' 'D']\n",
      "cat85 ['A' 'B' 'C' 'D']\n",
      "cat86 ['A' 'B' 'C' 'D']\n",
      "cat87 ['A' 'B' 'C' 'D']\n",
      "cat88 ['A' 'B' 'D' 'E']\n",
      "cat89 ['A' 'B' 'C' 'D' 'E' 'G' 'H' 'I']\n",
      "cat90 ['A' 'B' 'C' 'D' 'E' 'F' 'G']\n",
      "cat91 ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H']\n",
      "cat92 ['A' 'B' 'C' 'D' 'F' 'H' 'I']\n",
      "cat93 ['A' 'B' 'C' 'D' 'E']\n",
      "cat94 ['A' 'B' 'C' 'D' 'E' 'F' 'G']\n",
      "cat95 ['A' 'B' 'C' 'D' 'E']\n",
      "cat96 ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'I']\n",
      "cat97 ['A' 'B' 'C' 'D' 'E' 'F' 'G']\n",
      "cat98 ['A' 'B' 'C' 'D' 'E']\n",
      "cat99 ['C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'M' 'N' 'O' 'P' 'R' 'S' 'T']\n",
      "cat100 ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O']\n",
      "cat101 ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'Q' 'R' 'S'\n",
      " 'U']\n",
      "cat102 ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'J']\n",
      "cat103 ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'N']\n",
      "cat104 ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q']\n",
      "cat105 ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R'\n",
      " 'S' 'T']\n",
      "cat106 ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'R']\n",
      "cat107 ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R'\n",
      " 'S' 'U']\n",
      "cat108 ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K']\n",
      "cat109 84\n",
      "cat110 131\n",
      "cat111 ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'I' 'K' 'M' 'O' 'Q' 'S' 'U' 'W' 'Y']\n",
      "cat112 ['A' 'AA' 'AB' 'AC' 'AD' 'AE' 'AF' 'AG' 'AH' 'AI' 'AJ' 'AK' 'AL' 'AM' 'AN'\n",
      " 'AO' 'AP' 'AQ' 'AR' 'AS' 'AT' 'AU' 'AV' 'AW' 'AX' 'AY' 'B' 'BA' 'C' 'D'\n",
      " 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R' 'S' 'T' 'U' 'V'\n",
      " 'W' 'X' 'Y']\n",
      "cat113 61\n",
      "cat114 ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'I' 'J' 'L' 'N' 'O' 'Q' 'R' 'S' 'U' 'V' 'W'\n",
      " 'X']\n",
      "cat115 ['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R'\n",
      " 'S' 'T' 'U' 'W' 'X']\n",
      "cat116 326\n",
      "cont1 647\n",
      "cont2 [ 0.001149  0.001503  0.001966  0.002571  0.003362  0.004394  0.005742\n",
      "  0.007501  0.009792  0.012775  0.016651  0.021677  0.028177  0.036553\n",
      "  0.047297  0.061     0.078346  0.100099  0.127059  0.15999   0.199504\n",
      "  0.245921  0.299102  0.358319  0.422197  0.488789  0.555782  0.620805\n",
      "  0.681761  0.737068  0.785784  0.827585  0.862654]\n",
      "cont3 76\n",
      "cont4 112\n",
      "cont5 141\n",
      "cont6 2573\n",
      "cont7 5632\n",
      "cont8 201\n",
      "cont9 347\n",
      "cont10 174\n",
      "cont11 326\n",
      "cont12 328\n",
      "cont13 353\n",
      "cont14 18740\n",
      "loss 158223\n"
     ]
    }
   ],
   "source": [
    "for column in train.columns :\n",
    "    if train[column].nunique() < 60 :\n",
    "        print column, np.array(sorted(train[column].unique()))\n",
    "    else :\n",
    "        print column, train[column].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most of categorical features have a small number of distinct values\n",
    "### Numerical features also have not so many distinct values\n",
    "### Let's encode categorical features to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat10</th>\n",
       "      <th>cat100</th>\n",
       "      <th>cat101</th>\n",
       "      <th>cat102</th>\n",
       "      <th>cat103</th>\n",
       "      <th>cat104</th>\n",
       "      <th>cat105</th>\n",
       "      <th>cat106</th>\n",
       "      <th>cat107</th>\n",
       "      <th>...</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>id</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.245921</td>\n",
       "      <td>0.187583</td>\n",
       "      <td>0.789639</td>\n",
       "      <td>0.310061</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.30260</td>\n",
       "      <td>0.67135</td>\n",
       "      <td>1</td>\n",
       "      <td>2213.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.737068</td>\n",
       "      <td>0.592681</td>\n",
       "      <td>0.614134</td>\n",
       "      <td>0.885834</td>\n",
       "      <td>0.438917</td>\n",
       "      <td>0.436585</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>2</td>\n",
       "      <td>1283.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.358319</td>\n",
       "      <td>0.484196</td>\n",
       "      <td>0.236924</td>\n",
       "      <td>0.397069</td>\n",
       "      <td>0.289648</td>\n",
       "      <td>0.315545</td>\n",
       "      <td>0.27320</td>\n",
       "      <td>0.26076</td>\n",
       "      <td>5</td>\n",
       "      <td>3005.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555782</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.373816</td>\n",
       "      <td>0.422268</td>\n",
       "      <td>0.440945</td>\n",
       "      <td>0.391128</td>\n",
       "      <td>0.31796</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>10</td>\n",
       "      <td>939.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159990</td>\n",
       "      <td>0.527991</td>\n",
       "      <td>0.473202</td>\n",
       "      <td>0.704268</td>\n",
       "      <td>0.178193</td>\n",
       "      <td>0.247408</td>\n",
       "      <td>0.24564</td>\n",
       "      <td>0.22089</td>\n",
       "      <td>11</td>\n",
       "      <td>2763.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cat1  cat10  cat100  cat101  cat102  cat103  cat104  cat105  cat106  \\\n",
       "0     0      0       1       6       0       0       8       4       6   \n",
       "1     0      1      11       5       0       0       4       4       8   \n",
       "2     0      1      11      14       0       1       4       5       7   \n",
       "3     1      0       8       3       0       0       4       4       8   \n",
       "4     0      1       5       9       0       0       3       4      10   \n",
       "\n",
       "   cat107   ...        cont2     cont3     cont4     cont5     cont6  \\\n",
       "0       9   ...     0.245921  0.187583  0.789639  0.310061  0.718367   \n",
       "1      10   ...     0.737068  0.592681  0.614134  0.885834  0.438917   \n",
       "2       5   ...     0.358319  0.484196  0.236924  0.397069  0.289648   \n",
       "3      10   ...     0.555782  0.527991  0.373816  0.422268  0.440945   \n",
       "4       6   ...     0.159990  0.527991  0.473202  0.704268  0.178193   \n",
       "\n",
       "      cont7    cont8    cont9  id     loss  \n",
       "0  0.335060  0.30260  0.67135   1  2213.18  \n",
       "1  0.436585  0.60087  0.35127   2  1283.60  \n",
       "2  0.315545  0.27320  0.26076   5  3005.09  \n",
       "3  0.391128  0.31796  0.32128  10   939.85  \n",
       "4  0.247408  0.24564  0.22089  11  2763.85  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for column in all_data :\n",
    "    encoder = LabelEncoder()\n",
    "    if column.startswith('cat') :\n",
    "        all_data[column] = encoder.fit_transform(all_data[column])\n",
    "        \n",
    "all_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = all_data[:train.shape[0]]\n",
    "test = all_data[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold out set for parameters tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_local, validation = train_test_split(\n",
    "    train, \n",
    "    test_size = 0.2, \n",
    "    random_state = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best constant result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min error: 1807.09, optimal constant prediction: 2110.00\n",
      "Mean target: 3040.71, median target: 2114.15\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "scores = []\n",
    "\n",
    "for C in np.linspace(1000, 4000, 301) :\n",
    "    p = np.ones(validation.shape[0]) * C\n",
    "    score = mean_absolute_error(p, validation['loss'])\n",
    "    scores.append((score, C))\n",
    "\n",
    "print 'Min error: %.2f, optimal constant prediction: %.2f' % min(scores)\n",
    "print 'Mean target: %.2f, median target: %.2f' % (validation['loss'].mean(), validation['loss'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try GBDT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['cat1', 'cat10', 'cat100', 'cat101', 'cat102', 'cat103', 'cat104',\n",
       "       'cat105', 'cat106', 'cat107', 'cat108', 'cat109', 'cat11', 'cat110',\n",
       "       'cat111', 'cat112', 'cat113', 'cat114', 'cat115', 'cat116', 'cat12',\n",
       "       'cat13', 'cat14', 'cat15', 'cat16', 'cat17', 'cat18', 'cat19',\n",
       "       'cat2', 'cat20', 'cat21', 'cat22', 'cat23', 'cat24', 'cat25',\n",
       "       'cat26', 'cat27', 'cat28', 'cat29', 'cat3', 'cat30', 'cat31',\n",
       "       'cat32', 'cat33', 'cat34', 'cat35', 'cat36', 'cat37', 'cat38',\n",
       "       'cat39', 'cat4', 'cat40', 'cat41', 'cat42', 'cat43', 'cat44',\n",
       "       'cat45', 'cat46', 'cat47', 'cat48', 'cat49', 'cat5', 'cat50',\n",
       "       'cat51', 'cat52', 'cat53', 'cat54', 'cat55', 'cat56', 'cat57',\n",
       "       'cat58', 'cat59', 'cat6', 'cat60', 'cat61', 'cat62', 'cat63',\n",
       "       'cat64', 'cat65', 'cat66', 'cat67', 'cat68', 'cat69', 'cat7',\n",
       "       'cat70', 'cat71', 'cat72', 'cat73', 'cat74', 'cat75', 'cat76',\n",
       "       'cat77', 'cat78', 'cat79', 'cat8', 'cat80', 'cat81', 'cat82',\n",
       "       'cat83', 'cat84', 'cat85', 'cat86', 'cat87', 'cat88', 'cat89',\n",
       "       'cat9', 'cat90', 'cat91', 'cat92', 'cat93', 'cat94', 'cat95',\n",
       "       'cat96', 'cat97', 'cat98', 'cat99', 'cont1', 'cont10', 'cont11',\n",
       "       'cont12', 'cont13', 'cont14', 'cont2', 'cont3', 'cont4', 'cont5',\n",
       "       'cont6', 'cont7', 'cont8', 'cont9', 'id'], \n",
       "      dtype='|S6')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.array([column for column in all_data.columns if column != 'loss'])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = XGBRegressor(max_depth = 6, learning_rate = 0.2, n_estimators = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 120 ms, total: 1min 41s\n",
      "Wall time: 9.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "       learning_rate=0.2, max_delta_step=0, max_depth=6,\n",
       "       min_child_weight=1, missing=None, n_estimators=1000, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=True, subsample=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "model.fit(\n",
    "    train_local[features].values, \n",
    "    train_local['loss'].values, \n",
    "    eval_set = [(validation[features].values, validation['loss'].values)], \n",
    "    early_stopping_rounds = 5,\n",
    "    verbose = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200.1755015606748"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = model.predict(validation[features].values)\n",
    "\n",
    "score = mean_absolute_error(p, validation['loss'])\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's submit this result to a leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/indexing.py:465: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "test.loc[:, 'loss'] = model.predict(test[features].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test[['id', 'loss']].to_csv('xgboost_basic.csv', index = False)\n",
    "!gzip -f xgboost_basic.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public leaderboard is 1181.1 (Validation 1200.1) with 1000+ place\n",
    "### Let's fit again the model with the whole train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change estimators number\n",
    "# We add 10% more iterations to compensate more examples in the train set than in the train_local set\n",
    "model.n_estimators = int(model.best_iteration / 0.9)\n",
    "model.n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(train[features].values, train['loss'].values)\n",
    "\n",
    "test.loc[:, 'loss'] = model.predict(test[features].values)\n",
    "test[['id', 'loss']].to_csv('xgboost_basic_full.csv', index = False)\n",
    "!gzip -f xgboost_basic_full.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Public leaderboard is 1177.2 (Validation 1200.1). Still 1000+ place\n",
    "### Let's log-transform the target. Experience shows that this helps when you need to optimize MAE error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Increase iterations number and max depth, decrease learning rate. Without justification\n",
    "\n",
    "model = XGBRegressor(max_depth = 8, learning_rate = 0.1, n_estimators = 1000, silent = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 21s, sys: 176 ms, total: 4min 21s\n",
      "Wall time: 22.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, colsample_bylevel=1, colsample_bytree=1, gamma=0,\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=8,\n",
       "       min_child_weight=1, missing=None, n_estimators=1000, nthread=-1,\n",
       "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=0, silent=False, subsample=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "model.fit(\n",
    "    train_local[features].values, \n",
    "    np.log(train_local['loss'].values), \n",
    "    eval_set = [(\n",
    "        validation[features].values, \n",
    "        np.log(validation['loss'].values)\n",
    "    )], \n",
    "    early_stopping_rounds = 5,\n",
    "    verbose = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1157.0516700627627"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.exp(model.predict(validation[features].values))\n",
    "\n",
    "score = mean_absolute_error(p, validation['loss'])\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/pandas/core/indexing.py:288: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n"
     ]
    }
   ],
   "source": [
    "validation.loc[:, 'loss_xgboost'] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.n_estimators = int(model.best_iteration / 0.9)\n",
    "model.n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(train[features].values, np.log(train['loss'].values))\n",
    "test.loc[:, 'loss'] = np.exp(model.predict(test[features].values))\n",
    "test[['id', 'loss']].to_csv('xgboost_log_transform.csv', index = False)\n",
    "\n",
    "!gzip -f xgboost_log_transform.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1130.8 (Validation 1157.0) with ~750 place, much better\n",
    "## Other trick is to multiply prediction by a constant to compensate difference between MAE and MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = validation['loss_xgboost'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's find an optimal multiplication constant for validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min error: 1155.37, optimal prediction multiplicator: 1.027\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for prediction_multiplicator in np.linspace(0.95, 1.05, 101) :\n",
    "    score = mean_absolute_error(p * prediction_multiplicator, validation['loss'])\n",
    "    scores.append((score, prediction_multiplicator))\n",
    "\n",
    "M = min(scores)[1]\n",
    "\n",
    "validation.loc[:, 'loss_xgboost'] *= M\n",
    "print 'Min error: %.2f, optimal prediction multiplicator: %.3f' % min(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.loc[:, 'loss'] *= M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[['id', 'loss']].to_csv('xgboost_log_transform_multiplicated.csv', index = False)\n",
    "!gzip -f xgboost_log_transform_multiplicated.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1129.3 (Validation 1155.4) with ~750 place, slightly better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors histogram: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAFZCAYAAABqoQ2HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d2f123290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist(\n",
    "    validation['loss'] - validation.loc[:, 'loss_xgboost'], \n",
    "    bins = 40, \n",
    "    range = [-20000, 30000], \n",
    "    log = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## At the competition forum we can find one more beneficial transform:\n",
    "## Target offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "offset = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.n_estimators = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "model.fit(\n",
    "    train_local[features].values, \n",
    "    np.log(train_local['loss'].values + offset), \n",
    "    eval_set = [(\n",
    "        validation[features].values, \n",
    "        np.log(validation['loss'].values + offset)\n",
    "    )], \n",
    "    early_stopping_rounds = 15,\n",
    "    verbose = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = np.exp(model.predict(validation[features].values)) - offset\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for prediction_multiplicator in np.linspace(0.95, 1.05, 101) :\n",
    "    score = mean_absolute_error(p * prediction_multiplicator, validation['loss'])\n",
    "    scores.append((score, prediction_multiplicator))\n",
    "\n",
    "M = min(scores)[1]\n",
    "print 'Min error: %.2f, optimal prediction multiplicator: %.3f' % min(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.n_estimators = int(model.best_iteration / 0.9)\n",
    "model.n_estimators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(train[features].values, np.log(train['loss'].values + offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.loc[:, 'loss'] = np.exp(model.predict(test[features].values)) - offset\n",
    "test.loc[:, 'loss'] *= M\n",
    "\n",
    "test.loc[:, 'loss_xgboost'] = test.loc[:, 'loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test[['id', 'loss']].to_csv('xgboost_log_transform_multiplicated_offset.csv', index = False)\n",
    "!gzip -f xgboost_log_transform_multiplicated_offset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1128.1 (Validation 1151.90) with ~750 place, slightly better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try other GBDT model\n",
    "### You will need LightGBM executive and \"pylightgbm\" package to run this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pylightgbm.models import GBMRegressor\n",
    "os.environ['LIGHTGBM_EXEC'] = \"/root/tools/LightGBM/lightgbm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = GBMRegressor(\n",
    "    num_threads=-1,\n",
    "    learning_rate = 0.03,\n",
    "    num_iterations = 5000, \n",
    "    verbose = False, \n",
    "    early_stopping_round = 50,\n",
    "    feature_fraction = 0.8,\n",
    "    bagging_fraction = 0.8,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "model.fit(\n",
    "    train_local[features].values, \n",
    "    np.log(train_local['loss'].values + offset), \n",
    "    test_data = [(\n",
    "        validation[features].values, \n",
    "        np.log(validation['loss'].values + offset)\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = np.exp(model.predict(validation[features].values)) - offset\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for prediction_multiplicator in np.linspace(0.95, 1.05, 101) :\n",
    "    score = mean_absolute_error(p * prediction_multiplicator, validation['loss'])\n",
    "    scores.append((score, prediction_multiplicator))\n",
    "\n",
    "M = min(scores)[1]\n",
    "validation.loc[:, 'loss_lightgbm'] = p * M\n",
    "print 'Min error: %.2f, optimal prediction multiplicator: %.3f' % min(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = GBMRegressor(\n",
    "    num_threads=-1,\n",
    "    learning_rate = 0.03,\n",
    "    num_iterations = int(model.best_round / 0.9), \n",
    "    verbose = False, \n",
    "    early_stopping_round = 50,\n",
    "    feature_fraction = 0.8,\n",
    "    bagging_fraction = 0.8,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(train[features].values, np.log(train['loss'].values + offset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.loc[:, 'loss_lightgbm'] = np.exp(model.predict(test[features].values)) - offset\n",
    "test.loc[:, 'loss_lightgbm'] *= M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.loc[:, 'loss'] = test['loss_lightgbm']\n",
    "\n",
    "test[['id', 'loss']].to_csv('lightgbm_log_transform_multiplicated_offset.csv', index = False)\n",
    "!gzip -f lightgbm_log_transform_multiplicated_offset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1119.2 (Validation 1142.3) with ~550 place\n",
    "## Let's try to blend two models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for alpha in np.linspace(0.1, 0.9, 9) :\n",
    "    p = validation['loss_lightgbm'] * alpha + validation['loss_xgboost'] * (1 - alpha)\n",
    "    score = mean_absolute_error(p, validation['loss'])\n",
    "    scores.append((score, alpha))\n",
    "    \n",
    "print min(scores)\n",
    "alpha = min(scores)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.loc[:, 'loss'] = test['loss_lightgbm'] * alpha + test['loss_xgboost'] * (1 - alpha)\n",
    "test[['id', 'loss']].to_csv('blending_log_transform_multiplicated_offset.csv', index = False)\n",
    "!gzip -f blending_log_transform_multiplicated_offset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1118.2 with ~500 place\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning parameters can give you about 1114.0 score and 300 place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's analyze local validation and public leaderboard: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Validation | Leaderboard   |\n",
    "|------------|---------------|\n",
    "| 1141.8     | 1118.2        |\n",
    "| 1142.3     | 1119.2        |\n",
    "| 1152.2     | 1128.1        |\n",
    "| 1155.4     | 1129.3        |\n",
    "| 1157.0     | 1130.8        |\n",
    "| 1200.1     | 1177.2        | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can see good correspondence between local and leaderboard metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
